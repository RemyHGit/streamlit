# üß† Application de D√©tection de Biais - Pr√©diction d'AVC

Application Streamlit pour l'exploration de donn√©es et la d√©tection de biais dans le dataset Stroke Prediction.

## üìã Description

Cette application permet d'analyser le dataset **Stroke Prediction Dataset** de Kaggle et de d√©tecter les biais potentiels li√©s au **genre** et √† la **zone g√©ographique** (Rural/Urban) dans la pr√©diction du risque d'AVC.

## üìÅ Structure du Projet

```
PROJET/
‚îú‚îÄ‚îÄ app.py                          # Point d'entr√©e principal de l'application
‚îú‚îÄ‚îÄ pages/                          # Dossier contenant les pages de l'application
‚îÇ   ‚îú‚îÄ‚îÄ 1_Exploration_des_Donnees.py    # Page d'exploration des donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ 2_Detection_de_Biais.py         # Page de d√©tection de biais
‚îÇ   ‚îî‚îÄ‚îÄ 3_Modelisation.py               # Page de mod√©lisation (BONUS)
‚îú‚îÄ‚îÄ utils/                          # Dossier contenant les fonctions utilitaires
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ fairness.py                 # Fonctions de calcul des m√©triques de fairness
‚îú‚îÄ‚îÄ requirements.txt                # D√©pendances Python du projet
‚îú‚îÄ‚îÄ README.md                       # Documentation du projet
‚îî‚îÄ‚îÄ .gitignore                      # Fichiers √† ignorer par Git
```

### Contenu des Fichiers

#### `app.py`
- **Fonction principale** : Point d'entr√©e de l'application Streamlit
- **Fonctionnalit√©s** :
  - Configuration de la page (titre, ic√¥ne, layout)
  - T√©l√©chargement automatique du dataset depuis Kaggle via `kagglehub`
  - Nettoyage des donn√©es (normalisation de la colonne `age` en entier)
  - Mise en cache des donn√©es pour am√©liorer les performances
  - Stockage du dataframe dans `st.session_state` pour partage entre pages
  - Contenu de la page d'accueil (pr√©sentation du projet, contexte, probl√©matique)

#### `pages/1_Exploration_des_Donnees.py`
- **Fonction principale** : Exploration et visualisation des donn√©es
- **Contenu** :
  - 4 m√©triques KPIs (nombre de lignes, colonnes, taux de valeurs manquantes, distribution de la variable cible)
  - Aper√ßu interactif du dataframe
  - Description technique et signification des colonnes
  - 6 visualisations interactives (histogrammes, barres, corr√©lations, box plots, pie charts)
  - Filtres interactifs pour explorer les donn√©es

#### `pages/2_Detection_de_Biais.py`
- **Fonction principale** : D√©tection et analyse des biais dans les donn√©es
- **Contenu** :
  - Explication des biais analys√©s (genre, zone g√©ographique)
  - Calcul de 2 m√©triques de fairness (Parit√© D√©mographique, Ratio d'Impact Disproportionn√©)
  - Visualisations comparatives par groupe
  - Interpr√©tation des r√©sultats et recommandations

#### `pages/3_Modelisation.py`
- **Fonction principale** : Entra√Ænement et √©valuation de mod√®les de machine learning
- **Contenu** :
  - S√©lection des features et attributs sensibles
  - Pr√©paration des donn√©es (encodage, gestion des valeurs manquantes)
  - Entra√Ænement de mod√®les (Logistic Regression, Random Forest)
  - Calcul des m√©triques de performance (Accuracy, Precision, Recall, F1-Score)
  - Calcul des m√©triques de fairness sur les pr√©dictions
  - Comparaison des performances par groupe sensible
  - Matrices de confusion par groupe
  - Gestion du d√©s√©quilibre de classes avec `class_weight='balanced'`

#### `utils/fairness.py`
- **Fonction principale** : Impl√©mentation des m√©triques de fairness
- **Fonctions** :
  - `demographic_parity_difference()` : Calcule la diff√©rence de parit√© d√©mographique
  - `disparate_impact_ratio()` : Calcule le ratio d'impact disproportionn√©
  - `equalized_odds_difference()` : Calcule la diff√©rence d'√©galit√© des chances

## üöÄ Installation

1. **Installer les d√©pendances** :
```bash
pip install -r requirements.txt
```

2. **Configurer Kaggle** (pour t√©l√©charger le dataset) :
   - Cr√©er un compte sur [Kaggle](https://www.kaggle.com/)
   - T√©l√©charger votre fichier `kaggle.json` depuis les param√®tres de votre compte
   - Placer le fichier dans `~/.kaggle/` (Linux/Mac) ou `C:\Users\<username>\.kaggle\` (Windows)

## ‚ñ∂Ô∏è Lancement

Lancer l'application avec :
```bash
streamlit run app.py
```

L'application s'ouvrira automatiquement dans votre navigateur √† l'adresse `http://localhost:8501`

## üìë Structure de l'Application

### Page 1 : üè† Accueil
- **Titre et pr√©sentation du dataset** : Description du Stroke Prediction Dataset
- **Contexte et probl√©matique** : Explication de l'importance de la pr√©diction d'AVC et des enjeux li√©s aux biais
- **Navigation** : Acc√®s aux autres pages via la barre lat√©rale de Streamlit

### Page 2 : üìä Exploration des Donn√©es
- **4 KPIs** : 
  - Nombre total de lignes
  - Nombre de colonnes
  - Taux de valeurs manquantes
  - Distribution de la variable cible (taux d'AVC)
- **Aper√ßu des donn√©es** : DataFrame interactif avec les 100 premi√®res lignes
- **Description des colonnes** : Tableau avec type, valeurs manquantes, valeurs uniques et exemples
- **Signification des colonnes** : Explications en langage naturel de chaque colonne
- **6 visualisations** :
  1. Distribution de la variable cible (histogramme)
  2. Comparaison par genre (graphique en barres)
  3. Comparaison par zone g√©ographique (graphique en barres)
  4. Matrice de corr√©lations (heatmap)
  5. Distribution de l'√¢ge par statut AVC (box plot)
  6. R√©partition par genre (pie chart)
- **Filtres interactifs** (BONUS) : Filtrage par genre, zone g√©ographique, statut marital, etc.

### Page 3 : ‚ö†Ô∏è D√©tection de Biais
- **S√©lection de l'attribut sensible** : Choix entre genre ou zone g√©ographique
- **Explication du biais analys√©** : Pourquoi c'est probl√©matique et quel est l'impact r√©el
- **2 m√©triques de fairness** :
  1. **Parit√© D√©mographique** : Diff√©rence maximale entre les taux de pr√©diction positive par groupe
  2. **Ratio d'Impact Disproportionn√©** : Ratio entre le taux du groupe non-privil√©gi√© et celui du groupe privil√©gi√©
- **Visualisations des r√©sultats** : Graphiques en barres comparant les taux par groupe
- **Interpr√©tation** : Analyse concr√®te du biais d√©tect√©, identification du groupe d√©favoris√©, impact r√©el et recommandations

### Page 4 : ü§ñ Mod√©lisation (BONUS)
- **Pr√©paration des donn√©es** :
  - S√©lection des variables √† utiliser comme features
  - Choix de l'attribut sensible pour l'analyse de fairness
  - Gestion des valeurs manquantes (m√©diane pour num√©riques, mode pour cat√©gorielles)
  - Encodage des variables cat√©gorielles
- **S√©lection du mod√®le** :
  - Logistic Regression ou Random Forest
  - Option `class_weight='balanced'` pour g√©rer le d√©s√©quilibre de classes
  - Param√®tres ajustables pour Random Forest (nombre d'arbres, profondeur max)
- **Performances globales** : Accuracy, Precision, Recall, F1-Score
- **Distribution des pr√©dictions** : Visualisation du nombre de pr√©dictions par classe
- **M√©triques de fairness sur les pr√©dictions** : Parit√© D√©mographique et Ratio d'Impact Disproportionn√©
- **Performances par groupe** : Comparaison des m√©triques (Accuracy, Precision, Recall, F1-Score) pour chaque groupe sensible
- **Matrices de confusion par groupe** : Visualisation des vrais/faux positifs et n√©gatifs pour chaque groupe

## üìö D√©finitions des Termes Techniques

### M√©triques de Performance

#### **Accuracy (Pr√©cision Globale)**
Pourcentage de pr√©dictions correctes parmi toutes les pr√©dictions. Formule : `(Vrais Positifs + Vrais N√©gatifs) / Total`

**Exemple** : Si un mod√®le pr√©dit correctement 95% des cas, l'Accuracy est de 0.95.

**Limitation** : Peut √™tre trompeuse en cas de d√©s√©quilibre de classes. Un mod√®le qui pr√©dit toujours la classe majoritaire aura une Accuracy √©lev√©e mais sera inutile.

#### **Precision (Pr√©cision)**
Proportion de pr√©dictions positives qui sont r√©ellement positives. Formule : `Vrais Positifs / (Vrais Positifs + Faux Positifs)`

**Exemple** : Si le mod√®le pr√©dit 100 AVC et que 80 sont r√©ellement des AVC, la Precision est de 0.80.

**Interpr√©tation** : Mesure la fiabilit√© des pr√©dictions positives. Une Precision √©lev√©e signifie peu de faux positifs.

#### **Recall (Rappel ou Sensibilit√©)**
Proportion de cas positifs r√©els qui sont correctement identifi√©s. Formule : `Vrais Positifs / (Vrais Positifs + Faux N√©gatifs)`

**Exemple** : S'il y a 100 AVC r√©els et que le mod√®le en d√©tecte 78, le Recall est de 0.78.

**Interpr√©tation** : Mesure la capacit√© du mod√®le √† trouver tous les cas positifs. Un Recall √©lev√© signifie peu de faux n√©gatifs (cas manqu√©s).

#### **F1-Score**
Moyenne harmonique entre Precision et Recall. Formule : `2 √ó (Precision √ó Recall) / (Precision + Recall)`

**Exemple** : Si Precision = 0.80 et Recall = 0.75, alors F1-Score = 2 √ó (0.80 √ó 0.75) / (0.80 + 0.75) ‚âà 0.77

**Interpr√©tation** : √âquilibre entre Precision et Recall. Utile quand il faut trouver un compromis entre √©viter les faux positifs et les faux n√©gatifs.

### M√©triques de Fairness (√âquit√©)

#### **Parit√© D√©mographique (Demographic Parity)**
Mesure la diff√©rence maximale entre les taux de pr√©diction positive par groupe d√©mographique. Plus la valeur est proche de 0, plus le mod√®le est √©quitable.

**Formule** : `max(taux_groupe_i) - min(taux_groupe_j)` pour tous les groupes i, j

**Exemple** : Si le groupe A a un taux de pr√©diction positive de 0.15 et le groupe B de 0.10, la diff√©rence est de 0.05.

**Interpr√©tation** : 
- **0.0** : Parfaite √©quit√© (tous les groupes ont le m√™me taux de pr√©diction positive)
- **> 0.1** : Biais potentiel significatif

#### **Ratio d'Impact Disproportionn√© (Disparate Impact Ratio)**
Ratio entre le taux de pr√©diction positive du groupe avec le taux le plus faible et celui du groupe avec le taux le plus √©lev√© (groupe de r√©f√©rence). Mesure si un groupe est syst√©matiquement d√©savantag√©.

**Formule** : `taux_groupe_taux_faible / taux_groupe_taux_√©lev√©`

**Note** : Dans cette application, les groupes "privil√©gi√©" et "non-privil√©gi√©" sont d√©termin√©s dynamiquement en fonction des taux r√©els observ√©s dans les donn√©es, sans pr√©supposer qu'un groupe sp√©cifique est privil√©gi√©.

**Exemple** : Si le groupe A a un taux de 0.10 et le groupe B (r√©f√©rence) de 0.15, le ratio est 0.10/0.15 = 0.67.

**Interpr√©tation** :
- **Entre 0.8 et 1.25** : Acceptable (pas de biais significatif)
- **< 0.8** : Le groupe non-privil√©gi√© est d√©savantag√© (trop peu de pr√©dictions positives)
- **> 1.25** : Le groupe privil√©gi√© est d√©savantag√© (trop de pr√©dictions positives)

#### **√âgalit√© des Chances (Equalized Odds)**
Mesure si le mod√®le a les m√™mes taux de vrais positifs (TPR) et de faux positifs (FPR) pour tous les groupes. Plus les diff√©rences sont proches de 0, plus le mod√®le est √©quitable.

**Formule** : 
- `TPR_diff = max(TPR_groupe_i) - min(TPR_groupe_j)`
- `FPR_diff = max(FPR_groupe_i) - min(FPR_groupe_j)`

**Interpr√©tation** : Un mod√®le √©quitable devrait avoir les m√™mes performances (taux d'erreurs) pour tous les groupes.

### Termes G√©n√©raux

#### **KPIs (Key Performance Indicators)**
Indicateurs cl√©s de performance. M√©triques importantes qui donnent une vue d'ensemble rapide de l'√©tat des donn√©es ou du mod√®le.

#### **Variable Cible (Target Variable)**
Variable que l'on cherche √† pr√©dire. Dans ce projet, c'est la colonne `stroke` (0 = pas d'AVC, 1 = AVC).

#### **Features (Caract√©ristiques)**
Variables d'entr√©e utilis√©es pour faire des pr√©dictions. Exemples : √¢ge, genre, hypertension, etc.

#### **Attribut Sensible (Sensitive Attribute)**
Caract√©ristique d√©mographique qui pourrait √™tre source de discrimination. Dans ce projet : genre et zone g√©ographique.

#### **Groupe Privil√©gi√© / Non-Privil√©gi√©**
Dans cette application, ces termes sont utilis√©s de mani√®re technique pour le calcul des m√©triques de fairness :
- **Groupe privil√©gi√© (r√©f√©rence)** : Groupe avec le taux de pr√©diction positive le plus √©lev√© dans les donn√©es observ√©es
- **Groupe non-privil√©gi√© (compar√©)** : Groupe avec le taux de pr√©diction positive le plus faible dans les donn√©es observ√©es

**Note importante** : La d√©termination de ces groupes se fait automatiquement et dynamiquement en fonction des donn√©es r√©elles, sans pr√©supposer qu'un groupe d√©mographique sp√©cifique est historiquement privil√©gi√©. L'objectif est de d√©tecter les disparit√©s dans les taux de pr√©diction, quelle que soit leur direction.

#### **D√©s√©quilibre de Classes (Class Imbalance)**
Situation o√π une classe (ex: pas d'AVC) est beaucoup plus fr√©quente que l'autre (ex: AVC). Cela peut amener le mod√®le √† toujours pr√©dire la classe majoritaire.

**Solution** : Utiliser `class_weight='balanced'` pour donner plus de poids aux exemples de la classe minoritaire.

#### **Matrice de Confusion (Confusion Matrix)**
Tableau qui montre les pr√©dictions correctes et incorrectes :
- **Vrais Positifs (TP)** : Cas positifs correctement pr√©dits
- **Vrais N√©gatifs (TN)** : Cas n√©gatifs correctement pr√©dits
- **Faux Positifs (FP)** : Cas n√©gatifs incorrectement pr√©dits comme positifs
- **Faux N√©gatifs (FN)** : Cas positifs incorrectement pr√©dits comme n√©gatifs

#### **Encodage (Encoding)**
Conversion de variables cat√©gorielles (texte) en nombres pour que les mod√®les puissent les utiliser. Exemple : "Male" ‚Üí 0, "Female" ‚Üí 1.

#### **Train/Test Split**
Division des donn√©es en deux ensembles :
- **Train** : Utilis√© pour entra√Æner le mod√®le
- **Test** : Utilis√© pour √©valuer les performances du mod√®le sur des donn√©es jamais vues

#### **Logistic Regression**
Mod√®le de machine learning lin√©aire qui pr√©dit la probabilit√© qu'un √©v√©nement se produise. Adapt√© pour la classification binaire (0 ou 1).

#### **Random Forest**
Mod√®le de machine learning qui combine plusieurs arbres de d√©cision pour faire des pr√©dictions plus robustes. Moins sensible au surapprentissage que les arbres individuels.

## üìä M√©triques de Fairness - D√©tails

### Parit√© D√©mographique
Mesure la diff√©rence maximale entre les taux de pr√©diction positive par groupe. Plus proche de 0 = plus √©quitable.

**Utilisation** : D√©tecte si certains groupes re√ßoivent syst√©matiquement plus ou moins de pr√©dictions positives que d'autres.

### Ratio d'Impact Disproportionn√© (DI)
Ratio entre le taux de pr√©diction positive du groupe non-privil√©gi√© et celui du groupe privil√©gi√©. 
- **Ratio entre 0.8 et 1.25** = acceptable
- **Ratio < 0.8 ou > 1.25** = biais potentiel

**Utilisation** : Standard l√©gal utilis√© aux √âtats-Unis pour d√©tecter la discrimination. Un ratio < 0.8 indique une discrimination potentielle.

## üõ†Ô∏è Technologies Utilis√©es

- **Streamlit** : Framework Python pour cr√©er des applications web interactives rapidement
- **Pandas** : Biblioth√®que Python pour la manipulation et l'analyse de donn√©es
- **NumPy** : Biblioth√®que Python pour les calculs num√©riques
- **Plotly** : Biblioth√®que Python pour cr√©er des visualisations interactives
- **Scikit-learn** : Biblioth√®que Python pour le machine learning (mod√®les, m√©triques, pr√©processing)
- **Kagglehub** : Biblioth√®que Python pour t√©l√©charger facilement des datasets depuis Kaggle

## üìù Notes Importantes

- **T√©l√©chargement automatique** : Le dataset est automatiquement t√©l√©charg√© lors du premier lancement via `kagglehub`
- **Mise en cache** : Les donn√©es sont mises en cache avec `@st.cache_data` pour am√©liorer les performances lors des rechargements
- **Nettoyage des donn√©es** : La colonne `age` est automatiquement normalis√©e en entier (valeurs manquantes remplac√©es par la m√©diane)
- **Connexion internet requise** : L'application n√©cessite une connexion internet pour t√©l√©charger le dataset la premi√®re fois
- **Gestion du d√©s√©quilibre** : La page de mod√©lisation propose l'option `class_weight='balanced'` pour g√©rer le d√©s√©quilibre de classes
- **Navigation** : L'application utilise la navigation native multi-pages de Streamlit (dossier `pages/`)

## üîó Liens Utiles

- [Dataset Kaggle - Stroke Prediction](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset)
- [Documentation Streamlit](https://docs.streamlit.io/)
- [Documentation Plotly](https://plotly.com/python/)
- [Documentation Scikit-learn](https://scikit-learn.org/stable/)
- [Fairness in Machine Learning - Google](https://developers.google.com/machine-learning/fairness-overview)
