import streamlit as st
import pandas as pd
import plotly.express as px
from utils.fairness import demographic_parity_difference, disparate_impact_ratio

st.title("‚ö†Ô∏è D√©tection de Biais")
st.markdown("---")

if 'df' not in st.session_state:
    st.error("Les donn√©es n'ont pas √©t√© charg√©es. Veuillez retourner √† la page d'accueil.")
    st.stop()

df = st.session_state['df']

if 'stroke' not in df.columns:
    st.error("La variable cible 'stroke' n'a pas √©t√© trouv√©e dans le dataset.")
    st.stop()

st.header("Analyse des Biais dans la Pr√©diction d'AVC")

st.subheader("üîç S√©lection de l'Attribut Sensible")

sensitive_attr = st.selectbox(
    "Choisir l'attribut sensible √† analyser",
    options=['gender', 'Residence_type'],
    format_func=lambda x: 'Genre' if x == 'gender' else 'Zone G√©ographique (Rural/Urban)'
)

if sensitive_attr not in df.columns:
    st.error(f"L'attribut '{sensitive_attr}' n'existe pas dans le dataset.")
    st.stop()

st.markdown("---")

st.subheader("üìñ Explication du Biais Analys√©")

if sensitive_attr == 'gender':
    st.markdown("""
    ### Attribut Sensible : Genre
    
    **Pourquoi c'est probl√©matique ?**
    
    Les diff√©rences de genre dans la d√©tection et le traitement des AVC peuvent avoir des cons√©quences graves :
    - Diff√©rents genres peuvent pr√©senter des sympt√¥mes d'AVC diff√©rents
    - Les mod√®les entra√Æn√©s sur des donn√©es d√©s√©quilibr√©es peuvent sous-estimer ou sur-estimer le risque pour certains genres
    - Cela peut entra√Æner des retards dans le diagnostic et le traitement, augmentant la mortalit√© et les s√©quelles
    
    **Impact r√©el** : Un biais dans la pr√©diction pourrait signifier que certains groupes √† risque √©lev√© ne recevraient pas les soins pr√©ventifs appropri√©s, tandis que d'autres groupes pourraient √™tre sur-trait√©s.
    """)
else:
    st.markdown("""
    ### Attribut Sensible : Zone G√©ographique (Rural/Urban)
    
    **Pourquoi c'est probl√©matique ?**
    
    Les disparit√©s g√©ographiques dans l'acc√®s aux soins de sant√© sont un probl√®me majeur :
    - Les zones rurales ont souvent moins d'acc√®s aux √©tablissements de sant√© sp√©cialis√©s
    - Les donn√©es peuvent √™tre biais√©es si elles proviennent principalement de zones urbaines
    - Un mod√®le biais√© pourrait perp√©tuer ces in√©galit√©s en sous-estimant les risques en zone rurale
    
    **Impact r√©el** : Un biais g√©ographique pourrait signifier que les patients ruraux √† risque √©lev√© ne seraient pas identifi√©s correctement, aggravant les disparit√©s d'acc√®s aux soins d√©j√† existantes.
    """)

st.markdown("---")

st.subheader("üìä M√©triques de Fairness")

col1, col2 = st.columns(2)

with col1:
    st.markdown("#### 1. Parit√© D√©mographique")

    dp_result = demographic_parity_difference(
        y_true=df['stroke'].values,
        y_pred=df['stroke'].values,
        sensitive_attribute=df[sensitive_attr].values
    )

    st.metric(
        "Diff√©rence de Parit√© D√©mographique",
        f"{dp_result['difference']:.4f}",
        help="Diff√©rence maximale entre les taux de pr√©diction positive par groupe. Plus proche de 0 = plus √©quitable."
    )

    st.markdown("**Taux par groupe :**")
    for group, rate in dp_result['rates'].items():
        st.write(f"- {group}: {rate:.4f} ({rate*100:.2f}%)")

with col2:
    st.markdown("#### 2. Ratio d'Impact Disproportionn√©")

    # d√©terminer dynamiquement les groupes privil√©gi√©/non-privil√©gi√© bas√© sur les taux r√©els
    unique_vals = df[sensitive_attr].unique()
    if len(unique_vals) >= 2:
        # calculer le taux d'AVC pour chaque groupe
        group_rates = {}
        for group in unique_vals:
            group_mask = df[sensitive_attr] == group
            if group_mask.sum() > 0:
                group_rates[group] = df.loc[group_mask, 'stroke'].mean()
        
        if len(group_rates) >= 2:
            # groupe avec le taux le plus √©lev√© = groupe de r√©f√©rence (privil√©gi√©)
            # groupe avec le taux le plus faible = groupe compar√© (non-privil√©gi√©)
            privileged = max(group_rates, key=group_rates.get)
            unprivileged = min(group_rates, key=group_rates.get)
        else:
            st.warning("Pas assez de groupes pour calculer le ratio DI")
            privileged = None
            unprivileged = None
    else:
        st.warning("Pas assez de groupes pour calculer le ratio DI")
        privileged = None
        unprivileged = None

    if privileged and unprivileged:
        di_result = disparate_impact_ratio(
            y_true=df['stroke'].values,
            y_pred=df['stroke'].values,
            sensitive_attribute=df[sensitive_attr].values,
            unprivileged_value=unprivileged,
            privileged_value=privileged
        )

        ratio = di_result['ratio']
        st.metric(
            "Ratio d'Impact Disproportionn√©",
            f"{ratio:.4f}",
            help="Ratio entre le taux du groupe non-privil√©gi√© et celui du groupe privil√©gi√©. Proche de 1 = √©quitable. < 0.8 ou > 1.25 indique un biais."
        )

        st.markdown("**Taux par groupe :**")
        st.write(f"- {unprivileged} (taux le plus faible): {di_result['unprivileged_rate']:.4f} ({di_result['unprivileged_rate']*100:.2f}%)")
        st.write(f"- {privileged} (taux le plus √©lev√© - r√©f√©rence): {di_result['privileged_rate']:.4f} ({di_result['privileged_rate']*100:.2f}%)")

        if ratio < 0.8:
            st.warning(f"‚ö†Ô∏è Biais d√©tect√© : Le groupe '{unprivileged}' a un taux significativement plus faible que '{privileged}' (< 0.8)")
        elif ratio > 1.25:
            st.warning(f"‚ö†Ô∏è Biais d√©tect√© : Le groupe '{unprivileged}' a un taux significativement plus √©lev√© que '{privileged}' (> 1.25)")
        else:
            st.success("‚úÖ Ratio dans la plage acceptable (0.8 - 1.25)")

st.markdown("---")

st.subheader("üìà Visualisation des R√©sultats")

if sensitive_attr in df.columns:
    group_rates = df.groupby(sensitive_attr)['stroke'].mean().reset_index()
    group_rates.columns = ['Groupe', 'Taux_AVC']
    group_rates['Taux_AVC_Pourcent'] = group_rates['Taux_AVC'] * 100

    fig = px.bar(
        group_rates,
        x='Groupe',
        y='Taux_AVC_Pourcent',
        title=f"Taux d'AVC par {sensitive_attr}",
        labels={'Taux_AVC_Pourcent': "Taux d'AVC (%)", 'Groupe': sensitive_attr},
        color='Groupe',
        text='Taux_AVC_Pourcent'
    )
    fig.update_traces(texttemplate='%{text:.2f}%', textposition='outside')
    st.plotly_chart(fig, use_container_width=True)

    group_counts = df.groupby(sensitive_attr)['stroke'].agg(['count', 'sum']).reset_index()
    group_counts.columns = ['Groupe', 'Total', 'AVC']
    group_counts['Taux'] = (group_counts['AVC'] / group_counts['Total'] * 100).round(2)
    st.dataframe(group_counts, use_container_width=True)

st.markdown("---")

st.subheader("üî¨ Comparaison D√©taill√©e par Groupe")

if sensitive_attr in df.columns:
    comparison_df = df.groupby([sensitive_attr, 'stroke']).size().reset_index(name='count')
    comparison_df['stroke_label'] = comparison_df['stroke'].map({0: 'Sans AVC', 1: 'Avec AVC'})

    fig = px.bar(
        comparison_df,
        x=sensitive_attr,
        y='count',
        color='stroke_label',
        title=f"Distribution des AVC par {sensitive_attr}",
        labels={'count': 'Nombre de patients'},
        color_discrete_map={'Sans AVC': '#4ECDC4', 'Avec AVC': '#FF6B6B'},
        barmode='group'
    )
    st.plotly_chart(fig, use_container_width=True)

st.markdown("---")

st.subheader("üí° Interpr√©tation")

if sensitive_attr == 'gender':
    st.markdown("""
    **Que signifie concr√®tement le biais d√©tect√© ?**
    
    Les m√©triques calcul√©es r√©v√®lent les diff√©rences dans les taux d'AVC observ√©s entre les groupes de genre.
    Une diff√©rence de parit√© d√©mographique √©lev√©e ou un ratio d'impact disproportionn√© √©loign√© de 1
    indique que les taux d'AVC ne sont pas √©quitablement r√©partis entre les diff√©rents genres.
    
    **Quel groupe est d√©favoris√© ?**
    
    Le groupe avec le taux d'AVC le plus faible pourrait √™tre sous-diagnostiqu√© ou avoir des facteurs
    de risque non pris en compte. Le groupe avec le taux le plus √©lev√© pourrait avoir des facteurs
    de risque sp√©cifiques ou b√©n√©ficier d'un meilleur acc√®s au diagnostic.
    
    **Quel serait l'impact r√©el de ce biais ?**
    
    Si un mod√®le de pr√©diction reproduit ces disparit√©s sans les comprendre, il pourrait :
    - Sous-estimer le risque pour certains groupes, retardant les interventions pr√©ventives
    - Sur-estimer le risque pour d'autres groupes, entra√Ænant des traitements inutiles
    - Perp√©tuer les in√©galit√©s existantes dans l'acc√®s aux soins
    
    **Recommandations pour r√©duire le biais :**
    
    1. **Collecte de donn√©es √©quilibr√©e** : S'assurer que le dataset contient une repr√©sentation √©quitable de tous les genres
    2. **Analyse par sous-groupes** : D√©velopper des mod√®les sp√©cifiques ou ajuster les seuils de d√©cision par groupe
    3. **Validation continue** : Surveiller r√©guli√®rement les performances du mod√®le par groupe d√©mographique
    4. **Transparence** : Documenter clairement les limitations et biais potentiels du mod√®le
    """)
else:
    st.markdown("""
    **Que signifie concr√®tement le biais d√©tect√© ?**
    
    Les m√©triques r√©v√®lent les diff√©rences dans les taux d'AVC entre les zones rurales et urbaines.
    Ces diff√©rences peuvent refl√©ter √† la fois des disparit√©s r√©elles dans la sant√© et des biais
    dans la collecte de donn√©es ou l'acc√®s aux soins.
    
    **Quel groupe est d√©favoris√© ?**
    
    Les zones rurales sont souvent d√©favoris√©es en termes d'acc√®s aux soins sp√©cialis√©s et aux
    technologies m√©dicales avanc√©es. Un taux d'AVC diff√©rentiel pourrait indiquer :
    - Des diff√©rences r√©elles dans les facteurs de risque (alimentation, activit√© physique, etc.)
    - Des diff√©rences dans l'acc√®s au diagnostic et au traitement
    - Des biais dans la collecte de donn√©es
    
    **Quel serait l'impact r√©el de ce biais ?**
    
    Un mod√®le biais√© g√©ographiquement pourrait :
    - Ignorer les besoins sp√©cifiques des populations rurales
    - Perp√©tuer les in√©galit√©s d'acc√®s aux soins
    - Ne pas tenir compte des facteurs environnementaux sp√©cifiques √† chaque zone
    
    **Recommandations pour r√©duire le biais :**
    
    1. **Donn√©es repr√©sentatives** : Inclure des donn√©es provenant de zones rurales et urbaines de mani√®re √©quilibr√©e
    2. **Facteurs contextuels** : Int√©grer des variables sp√©cifiques √† chaque zone (acc√®s aux soins, distance aux h√¥pitaux, etc.)
    3. **Mod√®les adaptatifs** : D√©velopper des mod√®les qui s'adaptent aux contextes g√©ographiques
    4. **√âquit√© g√©ographique** : S'assurer que les interventions m√©dicales sont accessibles √† tous, ind√©pendamment de la localisation
    """)

st.markdown("---")
st.subheader("üìã R√©sum√© des M√©triques")

metrics_summary = pd.DataFrame({
    'M√©trique': [
        'Diff√©rence de Parit√© D√©mographique',
        'Ratio d\'Impact Disproportionn√©'
    ],
    'Valeur': [
        f"{dp_result['difference']:.4f}",
        f"{di_result['ratio']:.4f}" if privileged and unprivileged else "N/A"
    ],
    'Interpr√©tation': [
        'Plus proche de 0 = plus √©quitable',
        'Entre 0.8 et 1.25 = acceptable'
    ]
})

st.dataframe(metrics_summary, use_container_width=True)
